{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10119520,"sourceType":"datasetVersion","datasetId":6243959}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nAPI_KEY = os.environ[\"GEMINI_API_KEY\"]\n\ntranscription_file_path = \"/kaggle/input/ggggggg5/transcription.txt\"\nwith open(transcription_file_path, \"r\") as file:\n    transcription = file.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:45:56.410423Z","iopub.execute_input":"2024-12-06T11:45:56.410807Z","iopub.status.idle":"2024-12-06T11:45:56.422115Z","shell.execute_reply.started":"2024-12-06T11:45:56.410767Z","shell.execute_reply":"2024-12-06T11:45:56.420820Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install  genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:46:05.625744Z","iopub.execute_input":"2024-12-06T11:46:05.626293Z","iopub.status.idle":"2024-12-06T11:46:18.118707Z","shell.execute_reply.started":"2024-12-06T11:46:05.626241Z","shell.execute_reply":"2024-12-06T11:46:18.117158Z"}},"outputs":[{"name":"stdout","text":"Collecting genai\n  Downloading genai-2.1.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: ipython<9.0.0,>=8.10.0 in /opt/conda/lib/python3.10/site-packages (from genai) (8.21.0)\nCollecting openai<0.28.0,>=0.27.0 (from genai)\n  Downloading openai-0.27.10-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from genai) (0.9.0)\nCollecting tiktoken<0.4.0,>=0.3.2 (from genai)\n  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (5.14.3)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython<9.0.0,>=8.10.0->genai) (4.9.0)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->genai) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->genai) (4.66.4)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai<0.28.0,>=0.27.0->genai) (3.9.5)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<0.4.0,>=0.3.2->genai) (2024.5.15)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython<9.0.0,>=8.10.0->genai) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython<9.0.0,>=8.10.0->genai) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.10.0->genai) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2024.6.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (4.0.3)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.10.0->genai) (1.16.0)\nDownloading genai-2.1.0-py3-none-any.whl (16 kB)\nDownloading openai-0.27.10-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken, openai, genai\nSuccessfully installed genai-2.1.0 openai-0.27.10 tiktoken-0.3.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport google.generativeai as genai\n\n# Configure the Gemini API\ngenai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n\n# Set generation configuration\ngeneration_config = {\n    \"temperature\": 1,\n    \"top_p\": 0.95,\n    \"top_k\": 40,\n    \"max_output_tokens\": 8192,\n    \"response_mime_type\": \"text/plain\",\n}\n\n# Initialize the model\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-1.5-flash\",\n    generation_config=generation_config,\n)\n\nwith open(transcription_file_path, \"r\") as file:\n    transcription = file.read()\n\n# Define the chat session\nchat_session = model.start_chat(\n    history=[]\n)\nprompt = (\n    f\"You are an AI assistant skilled in analyzing call-center dialogues. Your task is to extract the customer’s query from the conversation and rephrase it in the third person. \"\n    f\"Focus on the customer's core request or concern and output the query concisely, in a clear, third-person form. \"\n    f\"Do not include any summaries or extra explanations, just provide the query.\\n\\n\"\n    f\"Conversation:\\n{transcription}\\n\\n\"\n    f\"Output:\"\n)\n\n# Send the message to the model\nresponse = chat_session.send_message(prompt)\n\n\n# Print the response\nprint(\"Model Output:\", response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:00:20.747975Z","iopub.execute_input":"2024-12-06T12:00:20.748366Z","iopub.status.idle":"2024-12-06T12:00:22.136264Z","shell.execute_reply.started":"2024-12-06T12:00:20.748330Z","shell.execute_reply":"2024-12-06T12:00:22.135107Z"}},"outputs":[{"name":"stdout","text":"Model Output: The customer requested to rent a car from the airport, specifying a pick-up time of 1 p.m. on the 21st and a drop-off time of 1 p.m. on the 25th, and inquired about the availability of a Jeep Wrangler or a similar mid-size SUV.\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
